{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Lambda, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()\n",
    "df_train = pd.read_csv('labels.csv')\n",
    "df_test = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002a283a315af96eaea0e28e7163b21b</td>\n",
       "      <td>borzoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id               breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07         boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97               dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397            pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d            bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62    golden_retriever\n",
       "5  002211c81b498ef88e1b40b9abf84e1d  bedlington_terrier\n",
       "6  00290d3e1fdd27226ba27a8ce248ce85  bedlington_terrier\n",
       "7  002a283a315af96eaea0e28e7163b21b              borzoi\n",
       "8  003df8b8a8b05244b1d920bb6cf451f9             basenji\n",
       "9  0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_series = pd.Series(df_train['breed'])\n",
    "one_hot = pd.get_dummies(target_series, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    # Arguments\n",
    "        img_id: string\n",
    "        train_or_test: string 'train' or 'test'.\n",
    "        size: resize the original image.\n",
    "    # Returns\n",
    "        Image as numpy array.\n",
    "    \"\"\"\n",
    "    img = image.load_img(os.path.join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    #img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10222it [00:54, 187.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (10222, 299, 299, 3) size: 2,741,571,066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((len(df_train), IM_SIZE, IM_SIZE, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((one_hot_labels.shape), dtype=np.uint8)\n",
    "for i, img_id in tqdm(enumerate(df_train['id'])):\n",
    "    img = read_img(img_id, 'train', (IM_SIZE, IM_SIZE))\n",
    "    x_train[i] = img\n",
    "    y_train[i] = one_hot_labels[i]\n",
    "    \n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 120) (10222, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_class = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Xception and Inception bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(MODEL, data=x_train):\n",
    "    cnn_model = MODEL(include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3), weights='imagenet')\n",
    "    \n",
    "    inputs = Input((IM_SIZE, IM_SIZE, 3))\n",
    "    x = inputs\n",
    "    x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "    x = cnn_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs, x)\n",
    "\n",
    "    features = cnn_model.predict(data, batch_size=64, verbose=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222/10222 [==============================] - 1233s  \n",
      "10222/10222 [==============================] - 4087s   \n"
     ]
    }
   ],
   "source": [
    "inception_features = get_features(inception_v3.InceptionV3, x_train)\n",
    "xception_features = get_features(xception.Xception, x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222/10222 [==============================] - 2057s  \n"
     ]
    }
   ],
   "source": [
    "resnet_features = get_features(resnet50.ResNet50, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.concatenate([inception_features, xception_features, resnet_features], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-2)\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                          patience=10, verbose=1),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(features.shape[1:])\n",
    "x = inputs\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_class, activation='softmax')(x)\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               737400    \n",
      "=================================================================\n",
      "Total params: 737,400\n",
      "Trainable params: 737,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/150\n",
      "9199/9199 [==============================] - 2s - loss: 3.3606 - acc: 0.3608 - val_loss: 1.5680 - val_acc: 0.8231\n",
      "Epoch 2/150\n",
      "9199/9199 [==============================] - 0s - loss: 1.1878 - acc: 0.8219 - val_loss: 0.8055 - val_acc: 0.8866\n",
      "Epoch 3/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.7643 - acc: 0.8702 - val_loss: 0.6154 - val_acc: 0.8964\n",
      "Epoch 4/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.6174 - acc: 0.8907 - val_loss: 0.5318 - val_acc: 0.9120\n",
      "Epoch 5/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.5481 - acc: 0.8980 - val_loss: 0.4869 - val_acc: 0.9159\n",
      "Epoch 6/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.5043 - acc: 0.9018 - val_loss: 0.4625 - val_acc: 0.9101\n",
      "Epoch 7/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.4788 - acc: 0.9040 - val_loss: 0.4372 - val_acc: 0.9120\n",
      "Epoch 8/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.4571 - acc: 0.9078 - val_loss: 0.4233 - val_acc: 0.9130\n",
      "Epoch 9/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.4383 - acc: 0.9059 - val_loss: 0.4117 - val_acc: 0.9101\n",
      "Epoch 10/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.4267 - acc: 0.9089 - val_loss: 0.4019 - val_acc: 0.9238\n",
      "Epoch 11/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.4172 - acc: 0.9105 - val_loss: 0.3936 - val_acc: 0.9150\n",
      "Epoch 12/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.4047 - acc: 0.9118 - val_loss: 0.3866 - val_acc: 0.9208\n",
      "Epoch 13/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3964 - acc: 0.9125 - val_loss: 0.3802 - val_acc: 0.9189\n",
      "Epoch 14/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3914 - acc: 0.9162 - val_loss: 0.3755 - val_acc: 0.9169\n",
      "Epoch 15/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3839 - acc: 0.9146 - val_loss: 0.3715 - val_acc: 0.9189\n",
      "Epoch 16/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3801 - acc: 0.9158 - val_loss: 0.3673 - val_acc: 0.9198\n",
      "Epoch 17/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3749 - acc: 0.9193 - val_loss: 0.3649 - val_acc: 0.9169\n",
      "Epoch 18/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3653 - acc: 0.9211 - val_loss: 0.3626 - val_acc: 0.9189\n",
      "Epoch 19/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3635 - acc: 0.9179 - val_loss: 0.3581 - val_acc: 0.9228\n",
      "Epoch 20/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3619 - acc: 0.9198 - val_loss: 0.3552 - val_acc: 0.9189\n",
      "Epoch 21/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3582 - acc: 0.9183 - val_loss: 0.3540 - val_acc: 0.9189\n",
      "Epoch 22/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3520 - acc: 0.9224 - val_loss: 0.3524 - val_acc: 0.9198\n",
      "Epoch 23/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3520 - acc: 0.9213 - val_loss: 0.3494 - val_acc: 0.9179\n",
      "Epoch 24/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3452 - acc: 0.9227 - val_loss: 0.3475 - val_acc: 0.9179\n",
      "Epoch 25/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3470 - acc: 0.9230 - val_loss: 0.3458 - val_acc: 0.9169\n",
      "Epoch 26/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3430 - acc: 0.9217 - val_loss: 0.3445 - val_acc: 0.9179\n",
      "Epoch 27/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3402 - acc: 0.9231 - val_loss: 0.3426 - val_acc: 0.9169\n",
      "Epoch 28/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3389 - acc: 0.9200 - val_loss: 0.3408 - val_acc: 0.9189\n",
      "Epoch 29/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3359 - acc: 0.9242 - val_loss: 0.3401 - val_acc: 0.9208\n",
      "Epoch 30/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3332 - acc: 0.9243 - val_loss: 0.3382 - val_acc: 0.9198\n",
      "Epoch 31/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3323 - acc: 0.9243 - val_loss: 0.3372 - val_acc: 0.9189\n",
      "Epoch 32/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3317 - acc: 0.9246 - val_loss: 0.3360 - val_acc: 0.9189\n",
      "Epoch 33/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3285 - acc: 0.9228 - val_loss: 0.3351 - val_acc: 0.9189\n",
      "Epoch 34/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3268 - acc: 0.9229 - val_loss: 0.3338 - val_acc: 0.9208\n",
      "Epoch 35/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3280 - acc: 0.9217 - val_loss: 0.3336 - val_acc: 0.9179\n",
      "Epoch 36/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3239 - acc: 0.9248 - val_loss: 0.3323 - val_acc: 0.9198\n",
      "Epoch 37/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3251 - acc: 0.9240 - val_loss: 0.3312 - val_acc: 0.9169\n",
      "Epoch 38/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3221 - acc: 0.9233 - val_loss: 0.3303 - val_acc: 0.9208\n",
      "Epoch 39/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3223 - acc: 0.9231 - val_loss: 0.3296 - val_acc: 0.9189\n",
      "Epoch 40/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3181 - acc: 0.9279 - val_loss: 0.3283 - val_acc: 0.9218\n",
      "Epoch 41/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3213 - acc: 0.9253 - val_loss: 0.3282 - val_acc: 0.9208\n",
      "Epoch 42/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3165 - acc: 0.9297 - val_loss: 0.3272 - val_acc: 0.9228\n",
      "Epoch 43/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3134 - acc: 0.9286 - val_loss: 0.3264 - val_acc: 0.9208\n",
      "Epoch 44/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3131 - acc: 0.9274 - val_loss: 0.3259 - val_acc: 0.9189\n",
      "Epoch 45/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3165 - acc: 0.9259 - val_loss: 0.3255 - val_acc: 0.9179\n",
      "Epoch 46/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3147 - acc: 0.9276 - val_loss: 0.3248 - val_acc: 0.9179\n",
      "Epoch 47/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3117 - acc: 0.9259 - val_loss: 0.3246 - val_acc: 0.9189\n",
      "Epoch 48/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3116 - acc: 0.9263 - val_loss: 0.3240 - val_acc: 0.9189\n",
      "Epoch 49/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3087 - acc: 0.9267 - val_loss: 0.3228 - val_acc: 0.9189\n",
      "Epoch 50/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3112 - acc: 0.9266 - val_loss: 0.3226 - val_acc: 0.9208\n",
      "Epoch 51/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3082 - acc: 0.9269 - val_loss: 0.3219 - val_acc: 0.9189\n",
      "Epoch 52/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3109 - acc: 0.9274 - val_loss: 0.3215 - val_acc: 0.9189\n",
      "Epoch 53/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3094 - acc: 0.9267 - val_loss: 0.3212 - val_acc: 0.9189\n",
      "Epoch 54/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3039 - acc: 0.9306 - val_loss: 0.3205 - val_acc: 0.9198\n",
      "Epoch 55/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3059 - acc: 0.9288 - val_loss: 0.3198 - val_acc: 0.9208\n",
      "Epoch 56/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3041 - acc: 0.9285 - val_loss: 0.3193 - val_acc: 0.9208\n",
      "Epoch 57/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3034 - acc: 0.9273 - val_loss: 0.3193 - val_acc: 0.9198\n",
      "Epoch 58/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3042 - acc: 0.9271 - val_loss: 0.3188 - val_acc: 0.9218\n",
      "Epoch 59/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3012 - acc: 0.9279 - val_loss: 0.3181 - val_acc: 0.9198\n",
      "Epoch 60/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3007 - acc: 0.9319 - val_loss: 0.3175 - val_acc: 0.9179\n",
      "Epoch 61/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3028 - acc: 0.9288 - val_loss: 0.3175 - val_acc: 0.9169\n",
      "Epoch 62/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3014 - acc: 0.9281 - val_loss: 0.3170 - val_acc: 0.9189\n",
      "Epoch 63/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2992 - acc: 0.9281 - val_loss: 0.3168 - val_acc: 0.9189\n",
      "Epoch 64/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.3006 - acc: 0.9298 - val_loss: 0.3161 - val_acc: 0.9189\n",
      "Epoch 65/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2980 - acc: 0.9280 - val_loss: 0.3156 - val_acc: 0.9189\n",
      "Epoch 66/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2992 - acc: 0.9287 - val_loss: 0.3155 - val_acc: 0.9179\n",
      "Epoch 67/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2969 - acc: 0.9298 - val_loss: 0.3150 - val_acc: 0.9169\n",
      "Epoch 68/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2972 - acc: 0.9275 - val_loss: 0.3147 - val_acc: 0.9179\n",
      "Epoch 69/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2973 - acc: 0.9294 - val_loss: 0.3146 - val_acc: 0.9179\n",
      "Epoch 70/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2959 - acc: 0.9288 - val_loss: 0.3141 - val_acc: 0.9189\n",
      "Epoch 71/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2940 - acc: 0.9294 - val_loss: 0.3138 - val_acc: 0.9198\n",
      "Epoch 72/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2914 - acc: 0.9311 - val_loss: 0.3136 - val_acc: 0.9208\n",
      "Epoch 73/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2942 - acc: 0.9299 - val_loss: 0.3129 - val_acc: 0.9179\n",
      "Epoch 74/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2948 - acc: 0.9287 - val_loss: 0.3131 - val_acc: 0.9218\n",
      "Epoch 75/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2905 - acc: 0.9317 - val_loss: 0.3126 - val_acc: 0.9218\n",
      "Epoch 76/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2960 - acc: 0.9272 - val_loss: 0.3123 - val_acc: 0.9208\n",
      "Epoch 77/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2888 - acc: 0.9313 - val_loss: 0.3118 - val_acc: 0.9208\n",
      "Epoch 78/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2923 - acc: 0.9315 - val_loss: 0.3114 - val_acc: 0.9198\n",
      "Epoch 79/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2954 - acc: 0.9288 - val_loss: 0.3111 - val_acc: 0.9208\n",
      "Epoch 80/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2902 - acc: 0.9329 - val_loss: 0.3107 - val_acc: 0.9189\n",
      "Epoch 81/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2903 - acc: 0.9290 - val_loss: 0.3107 - val_acc: 0.9198\n",
      "Epoch 82/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2906 - acc: 0.9280 - val_loss: 0.3103 - val_acc: 0.9189\n",
      "Epoch 83/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2905 - acc: 0.9298 - val_loss: 0.3100 - val_acc: 0.9189\n",
      "Epoch 84/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2864 - acc: 0.9308 - val_loss: 0.3100 - val_acc: 0.9198\n",
      "Epoch 85/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2887 - acc: 0.9279 - val_loss: 0.3097 - val_acc: 0.9189\n",
      "Epoch 86/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2881 - acc: 0.9313 - val_loss: 0.3096 - val_acc: 0.9198\n",
      "Epoch 87/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2847 - acc: 0.9328 - val_loss: 0.3092 - val_acc: 0.9198\n",
      "Epoch 88/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2876 - acc: 0.9308 - val_loss: 0.3090 - val_acc: 0.9189\n",
      "Epoch 89/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2880 - acc: 0.9309 - val_loss: 0.3089 - val_acc: 0.9189\n",
      "Epoch 90/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2872 - acc: 0.9325 - val_loss: 0.3087 - val_acc: 0.9179\n",
      "Epoch 91/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2861 - acc: 0.9318 - val_loss: 0.3084 - val_acc: 0.9198\n",
      "Epoch 92/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2864 - acc: 0.9318 - val_loss: 0.3084 - val_acc: 0.9198\n",
      "Epoch 93/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2864 - acc: 0.9319 - val_loss: 0.3081 - val_acc: 0.9198\n",
      "Epoch 94/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2850 - acc: 0.9318 - val_loss: 0.3077 - val_acc: 0.9208\n",
      "Epoch 95/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2883 - acc: 0.9316 - val_loss: 0.3076 - val_acc: 0.9189\n",
      "Epoch 96/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2874 - acc: 0.9291 - val_loss: 0.3075 - val_acc: 0.9198\n",
      "Epoch 97/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2847 - acc: 0.9315 - val_loss: 0.3072 - val_acc: 0.9198\n",
      "Epoch 98/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2857 - acc: 0.9315 - val_loss: 0.3070 - val_acc: 0.9189\n",
      "Epoch 99/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2824 - acc: 0.9300 - val_loss: 0.3068 - val_acc: 0.9198\n",
      "Epoch 100/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2809 - acc: 0.9329 - val_loss: 0.3066 - val_acc: 0.9198\n",
      "Epoch 101/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2806 - acc: 0.9335 - val_loss: 0.3063 - val_acc: 0.9208\n",
      "Epoch 102/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2887 - acc: 0.9289 - val_loss: 0.3059 - val_acc: 0.9198\n",
      "Epoch 103/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2821 - acc: 0.9319 - val_loss: 0.3056 - val_acc: 0.9208\n",
      "Epoch 104/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2839 - acc: 0.9324 - val_loss: 0.3055 - val_acc: 0.9208\n",
      "Epoch 105/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2796 - acc: 0.9311 - val_loss: 0.3051 - val_acc: 0.9208\n",
      "Epoch 106/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2816 - acc: 0.9291 - val_loss: 0.3051 - val_acc: 0.9218\n",
      "Epoch 107/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2796 - acc: 0.9324 - val_loss: 0.3050 - val_acc: 0.9218\n",
      "Epoch 108/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2832 - acc: 0.9317 - val_loss: 0.3049 - val_acc: 0.9238\n",
      "Epoch 109/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2765 - acc: 0.9342 - val_loss: 0.3049 - val_acc: 0.9208\n",
      "Epoch 110/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2808 - acc: 0.9323 - val_loss: 0.3047 - val_acc: 0.9198\n",
      "Epoch 111/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2815 - acc: 0.9321 - val_loss: 0.3046 - val_acc: 0.9198\n",
      "Epoch 112/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2804 - acc: 0.9316 - val_loss: 0.3044 - val_acc: 0.9208\n",
      "Epoch 113/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2809 - acc: 0.9333 - val_loss: 0.3046 - val_acc: 0.9208\n",
      "Epoch 114/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2775 - acc: 0.9327 - val_loss: 0.3045 - val_acc: 0.9208\n",
      "Epoch 115/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2827 - acc: 0.9323 - val_loss: 0.3042 - val_acc: 0.9208\n",
      "Epoch 116/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2784 - acc: 0.9311 - val_loss: 0.3040 - val_acc: 0.9208\n",
      "Epoch 117/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2805 - acc: 0.9336 - val_loss: 0.3037 - val_acc: 0.9208\n",
      "Epoch 118/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2828 - acc: 0.9283 - val_loss: 0.3037 - val_acc: 0.9218\n",
      "Epoch 119/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2786 - acc: 0.9330 - val_loss: 0.3034 - val_acc: 0.9218\n",
      "Epoch 120/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2779 - acc: 0.9323 - val_loss: 0.3032 - val_acc: 0.9218\n",
      "Epoch 121/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2775 - acc: 0.9313 - val_loss: 0.3032 - val_acc: 0.9218\n",
      "Epoch 122/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2700 - acc: 0.9354 - val_loss: 0.3029 - val_acc: 0.9228\n",
      "Epoch 123/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2804 - acc: 0.9328 - val_loss: 0.3027 - val_acc: 0.9238\n",
      "Epoch 124/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2769 - acc: 0.9334 - val_loss: 0.3024 - val_acc: 0.9208\n",
      "Epoch 125/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2760 - acc: 0.9354 - val_loss: 0.3024 - val_acc: 0.9189\n",
      "Epoch 126/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2743 - acc: 0.9313 - val_loss: 0.3024 - val_acc: 0.9189\n",
      "Epoch 127/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2702 - acc: 0.9356 - val_loss: 0.3022 - val_acc: 0.9208\n",
      "Epoch 128/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2782 - acc: 0.9325 - val_loss: 0.3021 - val_acc: 0.9189\n",
      "Epoch 129/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2771 - acc: 0.9342 - val_loss: 0.3021 - val_acc: 0.9208\n",
      "Epoch 130/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2763 - acc: 0.9355 - val_loss: 0.3017 - val_acc: 0.9189\n",
      "Epoch 131/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2776 - acc: 0.9326 - val_loss: 0.3017 - val_acc: 0.9218\n",
      "Epoch 132/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2730 - acc: 0.9342 - val_loss: 0.3015 - val_acc: 0.9208\n",
      "Epoch 133/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2759 - acc: 0.9325 - val_loss: 0.3014 - val_acc: 0.9208\n",
      "Epoch 134/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2726 - acc: 0.9335 - val_loss: 0.3012 - val_acc: 0.9208\n",
      "Epoch 135/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2731 - acc: 0.9337 - val_loss: 0.3010 - val_acc: 0.9218\n",
      "Epoch 136/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2759 - acc: 0.9319 - val_loss: 0.3009 - val_acc: 0.9198\n",
      "Epoch 137/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2737 - acc: 0.9339 - val_loss: 0.3009 - val_acc: 0.9218\n",
      "Epoch 138/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2721 - acc: 0.9339 - val_loss: 0.3009 - val_acc: 0.9198\n",
      "Epoch 139/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2751 - acc: 0.9302 - val_loss: 0.3008 - val_acc: 0.9218\n",
      "Epoch 140/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2773 - acc: 0.9322 - val_loss: 0.3006 - val_acc: 0.9208\n",
      "Epoch 141/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2737 - acc: 0.9325 - val_loss: 0.3004 - val_acc: 0.9208\n",
      "Epoch 142/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2747 - acc: 0.9334 - val_loss: 0.3004 - val_acc: 0.9218\n",
      "Epoch 143/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2767 - acc: 0.9333 - val_loss: 0.3004 - val_acc: 0.9208\n",
      "Epoch 144/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2707 - acc: 0.9346 - val_loss: 0.3004 - val_acc: 0.9208\n",
      "Epoch 145/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2717 - acc: 0.9351 - val_loss: 0.3003 - val_acc: 0.9218\n",
      "Epoch 146/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2711 - acc: 0.9356 - val_loss: 0.3000 - val_acc: 0.9218\n",
      "Epoch 147/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2734 - acc: 0.9321 - val_loss: 0.3000 - val_acc: 0.9208\n",
      "Epoch 148/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2688 - acc: 0.9341 - val_loss: 0.2998 - val_acc: 0.9218\n",
      "Epoch 149/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2721 - acc: 0.9327 - val_loss: 0.2995 - val_acc: 0.9218\n",
      "Epoch 150/150\n",
      "9199/9199 [==============================] - 0s - loss: 0.2719 - acc: 0.9313 - val_loss: 0.2995 - val_acc: 0.9218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d00684f98>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, y_train, batch_size=128, epochs=150, validation_split=0.1, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10357it [00:28, 364.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images shape: (10357, 299, 299, 3) size: 2,777,778,471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = np.zeros((len(df_test), IM_SIZE, IM_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm(enumerate(df_test['id'])):\n",
    "    img = read_img(img_id, 'test', (IM_SIZE, IM_SIZE))\n",
    "    x_test[i] = img\n",
    "    \n",
    "print('Test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357/10357 [==============================] - 2416s   \n",
      "10357/10357 [==============================] - 1187s  \n",
      "10357/10357 [==============================] - 1971s   \n"
     ]
    }
   ],
   "source": [
    "test_x_features = get_features(xception.Xception, x_test)\n",
    "test_i_features = get_features(inception_v3.InceptionV3, x_test)\n",
    "test_resnet_features = get_features(resnet50.ResNet50, x_test)\n",
    "test_features = np.concatenate([test_i_features, test_x_features, test_resnet_features], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_features, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0.049060</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00225dcd3e4d2410dd53239f95c0352f</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054726</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002c2a3117c2193b4d26400ce431eebd</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.986311</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002c58d413a521ae8d1a5daeb35fc803</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002f80396f1e3db687c5932d7978b196</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0036c6bcec6031be9e62a257b1c3c442</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  000621fb3cbb32d8935728e48679680e       0.000051      0.000033   \n",
       "1  00102ee9d8eb90812350685311fe5890       0.000027      0.000024   \n",
       "2  0012a730dfa437f5f3613fb75efcd4ce       0.000034      0.011641   \n",
       "3  001510bc8570bbeee98c8d80c8a95ec1       0.001762      0.000170   \n",
       "4  001a5f3114548acdefa3d4da05474c2e       0.049060      0.000555   \n",
       "5  00225dcd3e4d2410dd53239f95c0352f       0.000653      0.013143   \n",
       "6  002c2a3117c2193b4d26400ce431eebd       0.000035      0.000053   \n",
       "7  002c58d413a521ae8d1a5daeb35fc803       0.000054      0.000050   \n",
       "8  002f80396f1e3db687c5932d7978b196       0.000007      0.000037   \n",
       "9  0036c6bcec6031be9e62a257b1c3c442       0.000194      0.000369   \n",
       "\n",
       "   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n",
       "0             0.000024  0.000010                        0.000018     0.000019   \n",
       "1             0.000041  0.000027                        0.000051     0.000168   \n",
       "2             0.000245  0.000221                        0.000103     0.000139   \n",
       "3             0.000069  0.000024                        0.000155     0.000150   \n",
       "4             0.000343  0.000039                        0.000276     0.000225   \n",
       "5             0.000793  0.004140                        0.000384     0.000649   \n",
       "6             0.000109  0.000056                        0.000048     0.000024   \n",
       "7             0.000079  0.000037                        0.000052     0.000120   \n",
       "8             0.000017  0.000031                        0.000011     0.000014   \n",
       "9             0.000362  0.000066                        0.000194     0.000082   \n",
       "\n",
       "   australian_terrier   basenji    basset        ...          toy_poodle  \\\n",
       "0            0.000019  0.000009  0.000009        ...            0.000023   \n",
       "1            0.000033  0.000035  0.000036        ...            0.000033   \n",
       "2            0.000062  0.000075  0.000235        ...            0.000118   \n",
       "3            0.000017  0.000137  0.000114        ...            0.000120   \n",
       "4            0.000328  0.000218  0.000192        ...            0.000461   \n",
       "5            0.000586  0.000864  0.000297        ...            0.054726   \n",
       "6            0.986311  0.000067  0.000012        ...            0.000027   \n",
       "7            0.000091  0.000031  0.000044        ...            0.000108   \n",
       "8            0.000004  0.000008  0.000003        ...            0.000004   \n",
       "9            0.000124  0.000041  0.000688        ...            0.000178   \n",
       "\n",
       "   toy_terrier    vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0     0.000032  0.000021      0.000013    0.000017                0.000013   \n",
       "1     0.000031  0.000030      0.000059    0.000054                0.000053   \n",
       "2     0.000185  0.000340      0.000509    0.000321                0.001896   \n",
       "3     0.000048  0.000052      0.000069    0.000041                0.000021   \n",
       "4     0.000537  0.000462      0.000298    0.000199                0.000100   \n",
       "5     0.000659  0.000468      0.000428    0.000272                0.000489   \n",
       "6     0.000029  0.000107      0.000033    0.000020                0.000032   \n",
       "7     0.000034  0.000039      0.000069    0.000039                0.000083   \n",
       "8     0.000003  0.000021      0.000010    0.000022                0.000006   \n",
       "9     0.000095  0.000367      0.000081    0.000172                0.000632   \n",
       "\n",
       "   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n",
       "0                     0.000017  0.000009                 0.000053   \n",
       "1                     0.000430  0.000026                 0.000069   \n",
       "2                     0.000049  0.000225                 0.000253   \n",
       "3                     0.000029  0.000195                 0.000008   \n",
       "4                     0.000268  0.000449                 0.000432   \n",
       "5                     0.000256  0.000250                 0.004086   \n",
       "6                     0.000043  0.000012                 0.000134   \n",
       "7                     0.001569  0.000036                 0.000120   \n",
       "8                     0.000006  0.000042                 0.000046   \n",
       "9                     0.000196  0.000051                 0.000171   \n",
       "\n",
       "   yorkshire_terrier  \n",
       "0           0.000034  \n",
       "1           0.000021  \n",
       "2           0.000153  \n",
       "3           0.000073  \n",
       "4           0.001543  \n",
       "5           0.000621  \n",
       "6           0.001218  \n",
       "7           0.000054  \n",
       "8           0.000004  \n",
       "9           0.000107  \n",
       "\n",
       "[10 rows x 121 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame(y_pred)\n",
    "col_names = one_hot.columns.values\n",
    "sub.columns = col_names\n",
    "\n",
    "sub.insert(0, 'id', df_test['id'])\n",
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('inc_exc_submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>ffeda8623d4eee33c6d1156a2ecbfcf8</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>fff1ec9e6e413275984966f745a313b0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.972087</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>fff74b59b758bbbf13a5793182a9bbe4</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>fff7d50d848e8014ac1e9172dc6762a3</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>fffbff22c1f51e3dc80c4bf04089545b</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  affenpinscher  afghan_hound  \\\n",
       "10352  ffeda8623d4eee33c6d1156a2ecbfcf8       0.000158      0.002164   \n",
       "10353  fff1ec9e6e413275984966f745a313b0       0.000021      0.000033   \n",
       "10354  fff74b59b758bbbf13a5793182a9bbe4       0.000077      0.000123   \n",
       "10355  fff7d50d848e8014ac1e9172dc6762a3       0.000298      0.000099   \n",
       "10356  fffbff22c1f51e3dc80c4bf04089545b       0.000119      0.001478   \n",
       "\n",
       "       african_hunting_dog  airedale  american_staffordshire_terrier  \\\n",
       "10352             0.000474  0.000282                        0.000255   \n",
       "10353             0.000072  0.000046                        0.000280   \n",
       "10354             0.001822  0.000045                        0.000030   \n",
       "10355             0.000036  0.000017                        0.000078   \n",
       "10356             0.000398  0.000130                        0.000224   \n",
       "\n",
       "       appenzeller  australian_terrier   basenji    basset        ...          \\\n",
       "10352     0.000304            0.000174  0.000192  0.000610        ...           \n",
       "10353     0.000020            0.000038  0.000027  0.000150        ...           \n",
       "10354     0.000090            0.000164  0.000141  0.000054        ...           \n",
       "10355     0.000041            0.000080  0.000034  0.000037        ...           \n",
       "10356     0.000302            0.000085  0.000084  0.000083        ...           \n",
       "\n",
       "       toy_poodle  toy_terrier    vizsla  walker_hound  weimaraner  \\\n",
       "10352    0.007343     0.000584  0.000219      0.000630    0.000501   \n",
       "10353    0.000021     0.000030  0.006166      0.000074    0.972087   \n",
       "10354    0.000171     0.000101  0.000122      0.000132    0.000043   \n",
       "10355    0.000866     0.000047  0.000082      0.000058    0.000018   \n",
       "10356    0.000059     0.000076  0.000145      0.000233    0.000214   \n",
       "\n",
       "       welsh_springer_spaniel  west_highland_white_terrier   whippet  \\\n",
       "10352                0.000504                     0.000113  0.000489   \n",
       "10353                0.000023                     0.000014  0.000121   \n",
       "10354                0.000125                     0.000071  0.000067   \n",
       "10355                0.000015                     0.000130  0.000030   \n",
       "10356                0.000065                     0.000100  0.001715   \n",
       "\n",
       "       wire-haired_fox_terrier  yorkshire_terrier  \n",
       "10352                 0.000698           0.000153  \n",
       "10353                 0.000059           0.000065  \n",
       "10354                 0.000157           0.000070  \n",
       "10355                 0.000138           0.000225  \n",
       "10356                 0.000367           0.000059  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
